=== Running /cygdrive/c/repo/cntk_github6/CNTK/x64/release/cntk.exe configFile=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/TIMIT_AdaptLearnRate.cntk currentDirectory=D:\TestPreparation\Speech\ASR RunDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu DataDir=D:\TestPreparation\Speech\ASR ConfigDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config OutputDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu DeviceId=-1 timestamping=true LibDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/../lib ScpDir=D:\TestPreparation\Speech\ASR MlfDir=D:\TestPreparation\Speech\ASR NdlDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config MelDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config ExpDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu/exp DeviceNumber=-1 TIMIT_TrainAdaptLR=[SGD=[maxEpochs=1]] TIMIT_TrainAdaptLR=[SGD=[epochSize=2048]] numMBsToShowResult=5
-------------------------------------------------------------------
Build info: 

		Built time: Apr  6 2016 09:34:06
		Last modified date: Tue Apr  5 15:50:31 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: c:\Tools\cub-1.4.1\
		CUDNN_PATH: c:\Tools\cudnn-4.0\cuda
		Build Branch: eldak/addingTimitExamplesToTests
		Build SHA1: 40db0b8fcc1e6ffd89b9357a636439c63130b589 (modified)
		Built by eldak on ELDAK-0
		Build Path: c:\repo\cntk_github6\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to D:\TestPreparation\Speech\ASR
04/06/2016 12:27:06: -------------------------------------------------------------------
04/06/2016 12:27:06: Build info: 

04/06/2016 12:27:06: 		Built time: Apr  6 2016 09:34:06
04/06/2016 12:27:06: 		Last modified date: Tue Apr  5 15:50:31 2016
04/06/2016 12:27:06: 		Build type: Release
04/06/2016 12:27:06: 		Build target: GPU
04/06/2016 12:27:06: 		With 1bit-SGD: yes
04/06/2016 12:27:06: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
04/06/2016 12:27:06: 		CUB_PATH: c:\Tools\cub-1.4.1\
04/06/2016 12:27:06: 		CUDNN_PATH: c:\Tools\cudnn-4.0\cuda
04/06/2016 12:27:06: 		Build Branch: eldak/addingTimitExamplesToTests
04/06/2016 12:27:06: 		Build SHA1: 40db0b8fcc1e6ffd89b9357a636439c63130b589 (modified)
04/06/2016 12:27:06: 		Built by eldak on ELDAK-0
04/06/2016 12:27:06: 		Build Path: c:\repo\cntk_github6\CNTK\Source\CNTK\
04/06/2016 12:27:06: -------------------------------------------------------------------

04/06/2016 12:27:06: Running on ELDAK-0 at 2016/04/06 12:27:06
04/06/2016 12:27:06: Command line: 
C:\repo\cntk_github6\CNTK\x64\release\cntk.exe  configFile=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/TIMIT_AdaptLearnRate.cntk  currentDirectory=D:\TestPreparation\Speech\ASR  RunDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu  DataDir=D:\TestPreparation\Speech\ASR  ConfigDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config  OutputDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu  DeviceId=-1  timestamping=true  LibDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/../lib  ScpDir=D:\TestPreparation\Speech\ASR  MlfDir=D:\TestPreparation\Speech\ASR  NdlDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config  MelDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config  ExpDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu/exp  DeviceNumber=-1  TIMIT_TrainAdaptLR=[SGD=[maxEpochs=1]]  TIMIT_TrainAdaptLR=[SGD=[epochSize=2048]]  numMBsToShowResult=5



04/06/2016 12:27:06: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
04/06/2016 12:27:06: command=TIMIT_TrainAdaptLR
precision=float
TIMIT_TrainAdaptLR=[
    action=train
    modelPath=$ExpDir$\TrainAdaptLR\model\cntkSpeech.dnn
    deviceId=$DeviceNumber$
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=792:512*3:183
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0
        minibatchSize=128
        learningRatesPerMB=0.1:1.0
        momentumPerMB=0:0.9
        dropoutRate=0.0
        maxEpochs=25
        AutoAdjust=[
            reduceLearnRateIfImproveLessThan=0
            loadBestModel=true
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
            autoAdjustLR=AdjustAfterEpoch
        ]
        clippingThresholdPerSample=1#INF
    ]
    reader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792	
     	scpFile=$ScpDir$\TIMIT.train.scp.fbank.fullpath
      ]
      labels=[
	mlfFile=$MlfDir$\TIMIT.train.align_cistate.mlf.cntk
        labelDim=183
	labelMappingFile=$MlfDir$\TIMIT.statelist
      ]
    ]
    cvReader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792
	scpFile=$ScpDir$\TIMIT.dev.scp.fbank.fullpath    
      ]
      labels=[
	mlfFile=$MlfDir$\TIMIT.dev.align_cistate.mlf.cntk
        labelDim=183	
	labelMappingFile=$MlfDir$\TIMIT.statelist
      ]
    ]
]
currentDirectory=D:\TestPreparation\Speech\ASR
RunDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu
DataDir=D:\TestPreparation\Speech\ASR
ConfigDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
OutputDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu
DeviceId=-1
timestamping=true
LibDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/../lib
ScpDir=D:\TestPreparation\Speech\ASR
MlfDir=D:\TestPreparation\Speech\ASR
NdlDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
MelDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
ExpDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu/exp
DeviceNumber=-1
TIMIT_TrainAdaptLR=[SGD=[maxEpochs=1]]
TIMIT_TrainAdaptLR=[SGD=[epochSize=2048]]
numMBsToShowResult=5

04/06/2016 12:27:06: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

04/06/2016 12:27:06: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
04/06/2016 12:27:06: command=TIMIT_TrainAdaptLR
precision=float
TIMIT_TrainAdaptLR=[
    action=train
    modelPath=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu/exp\TrainAdaptLR\model\cntkSpeech.dnn
    deviceId=-1
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=792:512*3:183
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0
        minibatchSize=128
        learningRatesPerMB=0.1:1.0
        momentumPerMB=0:0.9
        dropoutRate=0.0
        maxEpochs=25
        AutoAdjust=[
            reduceLearnRateIfImproveLessThan=0
            loadBestModel=true
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
            autoAdjustLR=AdjustAfterEpoch
        ]
        clippingThresholdPerSample=1#INF
    ]
    reader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792	
     	scpFile=D:\TestPreparation\Speech\ASR\TIMIT.train.scp.fbank.fullpath
      ]
      labels=[
	mlfFile=D:\TestPreparation\Speech\ASR\TIMIT.train.align_cistate.mlf.cntk
        labelDim=183
	labelMappingFile=D:\TestPreparation\Speech\ASR\TIMIT.statelist
      ]
    ]
    cvReader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792
	scpFile=D:\TestPreparation\Speech\ASR\TIMIT.dev.scp.fbank.fullpath    
      ]
      labels=[
	mlfFile=D:\TestPreparation\Speech\ASR\TIMIT.dev.align_cistate.mlf.cntk
        labelDim=183	
	labelMappingFile=D:\TestPreparation\Speech\ASR\TIMIT.statelist
      ]
    ]
]
currentDirectory=D:\TestPreparation\Speech\ASR
RunDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu
DataDir=D:\TestPreparation\Speech\ASR
ConfigDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
OutputDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu
DeviceId=-1
timestamping=true
LibDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/../lib
ScpDir=D:\TestPreparation\Speech\ASR
MlfDir=D:\TestPreparation\Speech\ASR
NdlDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
MelDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
ExpDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu/exp
DeviceNumber=-1
TIMIT_TrainAdaptLR=[SGD=[maxEpochs=1]]
TIMIT_TrainAdaptLR=[SGD=[epochSize=2048]]
numMBsToShowResult=5

04/06/2016 12:27:06: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

04/06/2016 12:27:06: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: TIMIT_AdaptLearnRate.cntk:command=TIMIT_TrainAdaptLR
configparameters: TIMIT_AdaptLearnRate.cntk:ConfigDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
configparameters: TIMIT_AdaptLearnRate.cntk:currentDirectory=D:\TestPreparation\Speech\ASR
configparameters: TIMIT_AdaptLearnRate.cntk:DataDir=D:\TestPreparation\Speech\ASR
configparameters: TIMIT_AdaptLearnRate.cntk:DeviceId=-1
configparameters: TIMIT_AdaptLearnRate.cntk:DeviceNumber=-1
configparameters: TIMIT_AdaptLearnRate.cntk:ExpDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu/exp
configparameters: TIMIT_AdaptLearnRate.cntk:LibDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/../lib
configparameters: TIMIT_AdaptLearnRate.cntk:MelDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
configparameters: TIMIT_AdaptLearnRate.cntk:MlfDir=D:\TestPreparation\Speech\ASR
configparameters: TIMIT_AdaptLearnRate.cntk:NdlDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
configparameters: TIMIT_AdaptLearnRate.cntk:numMBsToShowResult=5
configparameters: TIMIT_AdaptLearnRate.cntk:OutputDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu
configparameters: TIMIT_AdaptLearnRate.cntk:precision=float
configparameters: TIMIT_AdaptLearnRate.cntk:RunDir=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu
configparameters: TIMIT_AdaptLearnRate.cntk:ScpDir=D:\TestPreparation\Speech\ASR
configparameters: TIMIT_AdaptLearnRate.cntk:timestamping=true
configparameters: TIMIT_AdaptLearnRate.cntk:TIMIT_TrainAdaptLR=[
    action=train
    modelPath=F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu/exp\TrainAdaptLR\model\cntkSpeech.dnn
    deviceId=-1
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=792:512*3:183
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0
        minibatchSize=128
        learningRatesPerMB=0.1:1.0
        momentumPerMB=0:0.9
        dropoutRate=0.0
        maxEpochs=25
        AutoAdjust=[
            reduceLearnRateIfImproveLessThan=0
            loadBestModel=true
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
            autoAdjustLR=AdjustAfterEpoch
        ]
        clippingThresholdPerSample=1#INF
    ]
    reader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792	
     	scpFile=D:\TestPreparation\Speech\ASR\TIMIT.train.scp.fbank.fullpath
      ]
      labels=[
	mlfFile=D:\TestPreparation\Speech\ASR\TIMIT.train.align_cistate.mlf.cntk
        labelDim=183
	labelMappingFile=D:\TestPreparation\Speech\ASR\TIMIT.statelist
      ]
    ]
    cvReader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792
	scpFile=D:\TestPreparation\Speech\ASR\TIMIT.dev.scp.fbank.fullpath    
      ]
      labels=[
	mlfFile=D:\TestPreparation\Speech\ASR\TIMIT.dev.align_cistate.mlf.cntk
        labelDim=183	
	labelMappingFile=D:\TestPreparation\Speech\ASR\TIMIT.statelist
      ]
    ]
] [SGD=[maxEpochs=1]] [SGD=[epochSize=2048]]

04/06/2016 12:27:06: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
04/06/2016 12:27:06: Commands: TIMIT_TrainAdaptLR
04/06/2016 12:27:06: Precision = "float"
04/06/2016 12:27:06: CNTKModelPath: F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu/exp\TrainAdaptLR\model\cntkSpeech.dnn
04/06/2016 12:27:06: CNTKCommandTrainInfo: TIMIT_TrainAdaptLR : 1
04/06/2016 12:27:06: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 1

04/06/2016 12:27:06: ##############################################################################
04/06/2016 12:27:06: #                                                                            #
04/06/2016 12:27:06: # Action "train"                                                             #
04/06/2016 12:27:06: #                                                                            #
04/06/2016 12:27:06: ##############################################################################

04/06/2016 12:27:06: CNTKCommandTrainBegin: TIMIT_TrainAdaptLR
SimpleNetworkBuilder Using CPU
reading script file D:\TestPreparation\Speech\ASR\TIMIT.train.scp.fbank.fullpath ... 3696 entries
total 183 state names in state list D:\TestPreparation\Speech\ASR\TIMIT.statelist
htkmlfreader: reading MLF file D:\TestPreparation\Speech\ASR\TIMIT.train.align_cistate.mlf.cntk ... total 3696 entries
biggrowablevectorarray: creating disk backup store at 'F:\cygwin64\tmp\CNT80BF.tmp'
minibatchframesourcemulti: reading 1 feature sets and 1 label sets.......................................................................................................
minibatchframesourcemulti: read label set 0: 183 classes

minibatchframesourcemulti: feature set 0: 1124823 frames read from 3696 utterances
biggrowablevectorarray: disk backup store created, 1124823 frames, 339738624 bytes
reading script file D:\TestPreparation\Speech\ASR\TIMIT.dev.scp.fbank.fullpath ... 400 entries
total 183 state names in state list D:\TestPreparation\Speech\ASR\TIMIT.statelist
htkmlfreader: reading MLF file D:\TestPreparation\Speech\ASR\TIMIT.dev.align_cistate.mlf.cntk ... total 400 entries
biggrowablevectorarray: creating disk backup store at 'F:\cygwin64\tmp\CNT892C.tmp'
minibatchframesourcemulti: reading 1 feature sets and 1 label sets...................................................................................
minibatchframesourcemulti: read label set 0: 183 classes

minibatchframesourcemulti: feature set 0: 122487 frames read from 400 utterances
biggrowablevectorarray: disk backup store created, 122487 frames, 37748736 bytes

04/06/2016 12:27:09: Creating virgin network.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 30 nodes to process in pass 1.


Validating network. 20 nodes to process in pass 2.


Validating network, final pass.

Validating --> labels = InputValue() :  -> [183 x *]
Validating --> W3 = LearnableParameter() :  -> [183 x 512]
Validating --> W2 = LearnableParameter() :  -> [512 x 512]
Validating --> W1 = LearnableParameter() :  -> [512 x 512]
Validating --> W0 = LearnableParameter() :  -> [512 x 792]
Validating --> features = InputValue() :  -> [792 x *]
Validating --> MeanOfFeatures = Mean (features) : [792 x *] -> [792]
Validating --> InvStdOfFeatures = InvStdDev (features) : [792 x *] -> [792]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [792 x *], [792], [792] -> [792 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 792], [792 x *] -> [512 x *]
Validating --> B0 = LearnableParameter() :  -> [512 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [512 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
Validating --> W2*H2 = Times (W2, H2) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [512 x 1]
Validating --> W2*H2+B2 = Plus (W2*H2, B2) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
Validating --> H3 = Sigmoid (W2*H2+B2) : [512 x 1 x *] -> [512 x 1 x *]
Validating --> W3*H2 = Times (W3, H3) : [183 x 512], [512 x 1 x *] -> [183 x 1 x *]
Validating --> B3 = LearnableParameter() :  -> [183 x 1]
Validating --> HLast = Plus (W3*H2, B3) : [183 x 1 x *], [183 x 1] -> [183 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [183 x *], [183 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [183 x *], [183 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [183 x 1 x *] -> [183 x 1 x *]
Validating --> Prior = Mean (labels) : [183 x *] -> [183]
Validating --> LogOfPrior = Log (Prior) : [183] -> [183]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [183 x 1 x *], [183] -> [183 x 1 x *]


14 out of 30 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

04/06/2016 12:27:09: Created model with 30 nodes on CPU.

04/06/2016 12:27:09: Training criterion node(s):
04/06/2016 12:27:09: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

04/06/2016 12:27:09: Evaluation criterion node(s):

04/06/2016 12:27:09: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

04/06/2016 12:27:09: Precomputing --> 3 PreCompute nodes found.

04/06/2016 12:27:09: 	MeanOfFeatures = Mean()
04/06/2016 12:27:09: 	InvStdOfFeatures = InvStdDev()
04/06/2016 12:27:09: 	Prior = Mean()
minibatchiterator: epoch 0: frames [0..1124823] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
randomordering: 0 retries for 1124823 elements (0.0%) to ensure window condition
randomordering: recached sequence for seed 0: 128042, 767369, ...
recoverblock: recovering feature block 0 [0..65535)
recoverblock: recovering feature block 1 [65536..131071)
recoverblock: recovering feature block 2 [131072..196607)
recoverblock: recovering feature block 3 [196608..262143)
recoverblock: recovering feature block 4 [262144..327679)
recoverblock: recovering feature block 5 [327680..393215)
recoverblock: recovering feature block 6 [393216..458751)
recoverblock: recovering feature block 7 [458752..524287)
recoverblock: recovering feature block 8 [524288..589823)
recoverblock: recovering feature block 9 [589824..655359)
recoverblock: recovering feature block 10 [655360..720895)
recoverblock: recovering feature block 11 [720896..786431)
recoverblock: recovering feature block 12 [786432..851967)
recoverblock: recovering feature block 13 [851968..917503)
recoverblock: recovering feature block 14 [917504..983039)
recoverblock: recovering feature block 15 [983040..1048575)
recoverblock: recovering feature block 16 [1048576..1114111)
recoverblock: recovering feature block 17 [1114112..1179647)

04/06/2016 12:27:18: Precomputing --> Completed.


04/06/2016 12:27:19: Starting Epoch 1: learning rate per sample = 0.000781  effective momentum = 0.000000  momentum as time constant = 0.0 samples
minibatchiterator: epoch 0: frames [0..2048] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses

04/06/2016 12:27:19: Starting minibatch loop.
04/06/2016 12:27:19:  Epoch[ 1 of 1]-Minibatch[   1-   5, 31.25%]: SamplesSeen = 640; TrainLossPerSample =  5.09174385; EvalErr[0]PerSample = 0.96406250; TotalTime = 0.1020s; SamplesPerSecond = 6274.1
04/06/2016 12:27:19:  Epoch[ 1 of 1]-Minibatch[   6-  10, 62.50%]: SamplesSeen = 640; TrainLossPerSample =  4.91356621; EvalErr[0]PerSample = 0.93593750; TotalTime = 0.0848s; SamplesPerSecond = 7544.9
04/06/2016 12:27:19:  Epoch[ 1 of 1]-Minibatch[  11-  15, 93.75%]: SamplesSeen = 640; TrainLossPerSample =  4.93053589; EvalErr[0]PerSample = 0.96406250; TotalTime = 0.0821s; SamplesPerSecond = 7798.9
04/06/2016 12:27:19: Finished Epoch[ 1 of 1]: [Training Set] TrainLossPerSample = 4.9798694; TotalSamplesSeen = 2048; EvalErrPerSample = 0.95654297; AvgLearningRatePerSample = 0.00078125001; EpochTime=0.286643
minibatchiterator: epoch 0: frames [0..122487] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
randomordering: 0 retries for 122487 elements (0.0%) to ensure window condition
randomordering: recached sequence for seed 0: 53396, 47929, ...
recoverblock: recovering feature block 0 [0..65535)
recoverblock: recovering feature block 1 [65536..131071)
Final Results: Minibatch[1-957]: SamplesSeen = 122487    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.9014954    Perplexity = 134.49075    EvalErrorPrediction: ErrorPrediction/Sample = 0.95672194    
04/06/2016 12:27:29: Finished Epoch[ 1 of 1]: [Validation Set] TrainLossPerSample = 4.9014954; EvalErrPerSample = 0.95672194
04/06/2016 12:27:29: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160406132705.892167\Examples\Speech\TIMIT_AdaptLearnRate@release_cpu/exp\TrainAdaptLR\model\cntkSpeech.dnn'
biggrowablevectorarray: deleted disk backup store at 'F:\cygwin64\tmp\CNT892C.tmp'
biggrowablevectorarray: deleted disk backup store at 'F:\cygwin64\tmp\CNT80BF.tmp'
04/06/2016 12:27:29: CNTKCommandTrainEnd: TIMIT_TrainAdaptLR

04/06/2016 12:27:29: Action "train" complete.

04/06/2016 12:27:29: __COMPLETED__