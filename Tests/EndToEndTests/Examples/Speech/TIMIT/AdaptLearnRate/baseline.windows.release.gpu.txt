=== Running /cygdrive/c/repo/cntk_github6/CNTK/x64/release/cntk.exe configFile=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/TIMIT_AdaptLearnRate.cntk currentDirectory=D:\TestPreparation\Speech\ASR RunDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu DataDir=D:\TestPreparation\Speech\ASR ConfigDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config OutputDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu DeviceId=0 timestamping=true LibDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/../lib ScpDir=D:\TestPreparation\Speech\ASR MlfDir=D:\TestPreparation\Speech\ASR NdlDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config MelDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config ExpDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu/exp DeviceNumber=0 TIMIT_TrainAdaptLR=[SGD=[maxEpochs=1]] TIMIT_TrainAdaptLR=[SGD=[epochSize=2048]] numMBsToShowResult=5
-------------------------------------------------------------------
Build info: 

		Built time: Apr  6 2016 09:34:06
		Last modified date: Tue Apr  5 15:50:31 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: c:\Tools\cub-1.4.1\
		CUDNN_PATH: c:\Tools\cudnn-4.0\cuda
		Build Branch: eldak/addingTimitExamplesToTests
		Build SHA1: 40db0b8fcc1e6ffd89b9357a636439c63130b589 (modified)
		Built by eldak on ELDAK-0
		Build Path: c:\repo\cntk_github6\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to D:\TestPreparation\Speech\ASR
04/06/2016 12:26:45: -------------------------------------------------------------------
04/06/2016 12:26:45: Build info: 

04/06/2016 12:26:45: 		Built time: Apr  6 2016 09:34:06
04/06/2016 12:26:45: 		Last modified date: Tue Apr  5 15:50:31 2016
04/06/2016 12:26:45: 		Build type: Release
04/06/2016 12:26:45: 		Build target: GPU
04/06/2016 12:26:45: 		With 1bit-SGD: yes
04/06/2016 12:26:45: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
04/06/2016 12:26:45: 		CUB_PATH: c:\Tools\cub-1.4.1\
04/06/2016 12:26:45: 		CUDNN_PATH: c:\Tools\cudnn-4.0\cuda
04/06/2016 12:26:45: 		Build Branch: eldak/addingTimitExamplesToTests
04/06/2016 12:26:45: 		Build SHA1: 40db0b8fcc1e6ffd89b9357a636439c63130b589 (modified)
04/06/2016 12:26:45: 		Built by eldak on ELDAK-0
04/06/2016 12:26:45: 		Build Path: c:\repo\cntk_github6\CNTK\Source\CNTK\
04/06/2016 12:26:45: -------------------------------------------------------------------

04/06/2016 12:26:45: Running on ELDAK-0 at 2016/04/06 12:26:45
04/06/2016 12:26:45: Command line: 
C:\repo\cntk_github6\CNTK\x64\release\cntk.exe  configFile=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/TIMIT_AdaptLearnRate.cntk  currentDirectory=D:\TestPreparation\Speech\ASR  RunDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu  DataDir=D:\TestPreparation\Speech\ASR  ConfigDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config  OutputDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu  DeviceId=0  timestamping=true  LibDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/../lib  ScpDir=D:\TestPreparation\Speech\ASR  MlfDir=D:\TestPreparation\Speech\ASR  NdlDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config  MelDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config  ExpDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu/exp  DeviceNumber=0  TIMIT_TrainAdaptLR=[SGD=[maxEpochs=1]]  TIMIT_TrainAdaptLR=[SGD=[epochSize=2048]]  numMBsToShowResult=5



04/06/2016 12:26:45: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
04/06/2016 12:26:45: command=TIMIT_TrainAdaptLR
precision=float
TIMIT_TrainAdaptLR=[
    action=train
    modelPath=$ExpDir$\TrainAdaptLR\model\cntkSpeech.dnn
    deviceId=$DeviceNumber$
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=792:512*3:183
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0
        minibatchSize=128
        learningRatesPerMB=0.1:1.0
        momentumPerMB=0:0.9
        dropoutRate=0.0
        maxEpochs=25
        AutoAdjust=[
            reduceLearnRateIfImproveLessThan=0
            loadBestModel=true
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
            autoAdjustLR=AdjustAfterEpoch
        ]
        clippingThresholdPerSample=1#INF
    ]
    reader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792	
     	scpFile=$ScpDir$\TIMIT.train.scp.fbank.fullpath
      ]
      labels=[
	mlfFile=$MlfDir$\TIMIT.train.align_cistate.mlf.cntk
        labelDim=183
	labelMappingFile=$MlfDir$\TIMIT.statelist
      ]
    ]
    cvReader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792
	scpFile=$ScpDir$\TIMIT.dev.scp.fbank.fullpath    
      ]
      labels=[
	mlfFile=$MlfDir$\TIMIT.dev.align_cistate.mlf.cntk
        labelDim=183	
	labelMappingFile=$MlfDir$\TIMIT.statelist
      ]
    ]
]
currentDirectory=D:\TestPreparation\Speech\ASR
RunDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu
DataDir=D:\TestPreparation\Speech\ASR
ConfigDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
OutputDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu
DeviceId=0
timestamping=true
LibDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/../lib
ScpDir=D:\TestPreparation\Speech\ASR
MlfDir=D:\TestPreparation\Speech\ASR
NdlDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
MelDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
ExpDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu/exp
DeviceNumber=0
TIMIT_TrainAdaptLR=[SGD=[maxEpochs=1]]
TIMIT_TrainAdaptLR=[SGD=[epochSize=2048]]
numMBsToShowResult=5

04/06/2016 12:26:45: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

04/06/2016 12:26:45: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
04/06/2016 12:26:45: command=TIMIT_TrainAdaptLR
precision=float
TIMIT_TrainAdaptLR=[
    action=train
    modelPath=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu/exp\TrainAdaptLR\model\cntkSpeech.dnn
    deviceId=0
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=792:512*3:183
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0
        minibatchSize=128
        learningRatesPerMB=0.1:1.0
        momentumPerMB=0:0.9
        dropoutRate=0.0
        maxEpochs=25
        AutoAdjust=[
            reduceLearnRateIfImproveLessThan=0
            loadBestModel=true
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
            autoAdjustLR=AdjustAfterEpoch
        ]
        clippingThresholdPerSample=1#INF
    ]
    reader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792	
     	scpFile=D:\TestPreparation\Speech\ASR\TIMIT.train.scp.fbank.fullpath
      ]
      labels=[
	mlfFile=D:\TestPreparation\Speech\ASR\TIMIT.train.align_cistate.mlf.cntk
        labelDim=183
	labelMappingFile=D:\TestPreparation\Speech\ASR\TIMIT.statelist
      ]
    ]
    cvReader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792
	scpFile=D:\TestPreparation\Speech\ASR\TIMIT.dev.scp.fbank.fullpath    
      ]
      labels=[
	mlfFile=D:\TestPreparation\Speech\ASR\TIMIT.dev.align_cistate.mlf.cntk
        labelDim=183	
	labelMappingFile=D:\TestPreparation\Speech\ASR\TIMIT.statelist
      ]
    ]
]
currentDirectory=D:\TestPreparation\Speech\ASR
RunDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu
DataDir=D:\TestPreparation\Speech\ASR
ConfigDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
OutputDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu
DeviceId=0
timestamping=true
LibDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/../lib
ScpDir=D:\TestPreparation\Speech\ASR
MlfDir=D:\TestPreparation\Speech\ASR
NdlDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
MelDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
ExpDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu/exp
DeviceNumber=0
TIMIT_TrainAdaptLR=[SGD=[maxEpochs=1]]
TIMIT_TrainAdaptLR=[SGD=[epochSize=2048]]
numMBsToShowResult=5

04/06/2016 12:26:45: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

04/06/2016 12:26:45: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: TIMIT_AdaptLearnRate.cntk:command=TIMIT_TrainAdaptLR
configparameters: TIMIT_AdaptLearnRate.cntk:ConfigDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
configparameters: TIMIT_AdaptLearnRate.cntk:currentDirectory=D:\TestPreparation\Speech\ASR
configparameters: TIMIT_AdaptLearnRate.cntk:DataDir=D:\TestPreparation\Speech\ASR
configparameters: TIMIT_AdaptLearnRate.cntk:DeviceId=0
configparameters: TIMIT_AdaptLearnRate.cntk:DeviceNumber=0
configparameters: TIMIT_AdaptLearnRate.cntk:ExpDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu/exp
configparameters: TIMIT_AdaptLearnRate.cntk:LibDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config/../lib
configparameters: TIMIT_AdaptLearnRate.cntk:MelDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
configparameters: TIMIT_AdaptLearnRate.cntk:MlfDir=D:\TestPreparation\Speech\ASR
configparameters: TIMIT_AdaptLearnRate.cntk:NdlDir=C:\repo\cntk_github6\CNTK\Examples\Speech\Miscellaneous\TIMIT\config
configparameters: TIMIT_AdaptLearnRate.cntk:numMBsToShowResult=5
configparameters: TIMIT_AdaptLearnRate.cntk:OutputDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu
configparameters: TIMIT_AdaptLearnRate.cntk:precision=float
configparameters: TIMIT_AdaptLearnRate.cntk:RunDir=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu
configparameters: TIMIT_AdaptLearnRate.cntk:ScpDir=D:\TestPreparation\Speech\ASR
configparameters: TIMIT_AdaptLearnRate.cntk:timestamping=true
configparameters: TIMIT_AdaptLearnRate.cntk:TIMIT_TrainAdaptLR=[
    action=train
    modelPath=F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu/exp\TrainAdaptLR\model\cntkSpeech.dnn
    deviceId=0
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=792:512*3:183
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0
        minibatchSize=128
        learningRatesPerMB=0.1:1.0
        momentumPerMB=0:0.9
        dropoutRate=0.0
        maxEpochs=25
        AutoAdjust=[
            reduceLearnRateIfImproveLessThan=0
            loadBestModel=true
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
            autoAdjustLR=AdjustAfterEpoch
        ]
        clippingThresholdPerSample=1#INF
    ]
    reader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792	
     	scpFile=D:\TestPreparation\Speech\ASR\TIMIT.train.scp.fbank.fullpath
      ]
      labels=[
	mlfFile=D:\TestPreparation\Speech\ASR\TIMIT.train.align_cistate.mlf.cntk
        labelDim=183
	labelMappingFile=D:\TestPreparation\Speech\ASR\TIMIT.statelist
      ]
    ]
    cvReader=[
      readerType=HTKMLFReader
      readMethod=rollingWindow
      miniBatchMode=Partial
      randomize=Auto
      verbosity=1   
      features=[
	dim=792
	scpFile=D:\TestPreparation\Speech\ASR\TIMIT.dev.scp.fbank.fullpath    
      ]
      labels=[
	mlfFile=D:\TestPreparation\Speech\ASR\TIMIT.dev.align_cistate.mlf.cntk
        labelDim=183	
	labelMappingFile=D:\TestPreparation\Speech\ASR\TIMIT.statelist
      ]
    ]
] [SGD=[maxEpochs=1]] [SGD=[epochSize=2048]]

04/06/2016 12:26:45: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
04/06/2016 12:26:45: Commands: TIMIT_TrainAdaptLR
04/06/2016 12:26:45: Precision = "float"
04/06/2016 12:26:45: CNTKModelPath: F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu/exp\TrainAdaptLR\model\cntkSpeech.dnn
04/06/2016 12:26:45: CNTKCommandTrainInfo: TIMIT_TrainAdaptLR : 1
04/06/2016 12:26:45: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 1

04/06/2016 12:26:45: ##############################################################################
04/06/2016 12:26:45: #                                                                            #
04/06/2016 12:26:45: # Action "train"                                                             #
04/06/2016 12:26:45: #                                                                            #
04/06/2016 12:26:45: ##############################################################################

04/06/2016 12:26:45: CNTKCommandTrainBegin: TIMIT_TrainAdaptLR
SimpleNetworkBuilder Using GPU 0
reading script file D:\TestPreparation\Speech\ASR\TIMIT.train.scp.fbank.fullpath ... 3696 entries
total 183 state names in state list D:\TestPreparation\Speech\ASR\TIMIT.statelist
htkmlfreader: reading MLF file D:\TestPreparation\Speech\ASR\TIMIT.train.align_cistate.mlf.cntk ... total 3696 entries
biggrowablevectorarray: creating disk backup store at 'F:\cygwin64\tmp\CNT301E.tmp'
minibatchframesourcemulti: reading 1 feature sets and 1 label sets.......................................................................................................
minibatchframesourcemulti: read label set 0: 183 classes

minibatchframesourcemulti: feature set 0: 1124823 frames read from 3696 utterances
biggrowablevectorarray: disk backup store created, 1124823 frames, 339738624 bytes
reading script file D:\TestPreparation\Speech\ASR\TIMIT.dev.scp.fbank.fullpath ... 400 entries
total 183 state names in state list D:\TestPreparation\Speech\ASR\TIMIT.statelist
htkmlfreader: reading MLF file D:\TestPreparation\Speech\ASR\TIMIT.dev.align_cistate.mlf.cntk ... total 400 entries
biggrowablevectorarray: creating disk backup store at 'F:\cygwin64\tmp\CNT38F9.tmp'
minibatchframesourcemulti: reading 1 feature sets and 1 label sets...................................................................................
minibatchframesourcemulti: read label set 0: 183 classes

minibatchframesourcemulti: feature set 0: 122487 frames read from 400 utterances
biggrowablevectorarray: disk backup store created, 122487 frames, 37748736 bytes

04/06/2016 12:26:48: Creating virgin network.
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 30 nodes to process in pass 1.


Validating network. 20 nodes to process in pass 2.


Validating network, final pass.

Validating --> labels = InputValue() :  -> [183 x *]
Validating --> W3 = LearnableParameter() :  -> [183 x 512]
Validating --> W2 = LearnableParameter() :  -> [512 x 512]
Validating --> W1 = LearnableParameter() :  -> [512 x 512]
Validating --> W0 = LearnableParameter() :  -> [512 x 792]
Validating --> features = InputValue() :  -> [792 x *]
Validating --> MeanOfFeatures = Mean (features) : [792 x *] -> [792]
Validating --> InvStdOfFeatures = InvStdDev (features) : [792 x *] -> [792]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [792 x *], [792], [792] -> [792 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 792], [792 x *] -> [512 x *]
Validating --> B0 = LearnableParameter() :  -> [512 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [512 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
Validating --> W2*H2 = Times (W2, H2) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [512 x 1]
Validating --> W2*H2+B2 = Plus (W2*H2, B2) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
Validating --> H3 = Sigmoid (W2*H2+B2) : [512 x 1 x *] -> [512 x 1 x *]
Validating --> W3*H2 = Times (W3, H3) : [183 x 512], [512 x 1 x *] -> [183 x 1 x *]
Validating --> B3 = LearnableParameter() :  -> [183 x 1]
Validating --> HLast = Plus (W3*H2, B3) : [183 x 1 x *], [183 x 1] -> [183 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [183 x *], [183 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [183 x *], [183 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [183 x 1 x *] -> [183 x 1 x *]
Validating --> Prior = Mean (labels) : [183 x *] -> [183]
Validating --> LogOfPrior = Log (Prior) : [183] -> [183]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [183 x 1 x *], [183] -> [183 x 1 x *]


14 out of 30 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

04/06/2016 12:26:49: Created model with 30 nodes on GPU 0.

04/06/2016 12:26:49: Training criterion node(s):
04/06/2016 12:26:49: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

04/06/2016 12:26:49: Evaluation criterion node(s):

04/06/2016 12:26:49: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

04/06/2016 12:26:49: Precomputing --> 3 PreCompute nodes found.

04/06/2016 12:26:49: 	MeanOfFeatures = Mean()
04/06/2016 12:26:49: 	InvStdOfFeatures = InvStdDev()
04/06/2016 12:26:49: 	Prior = Mean()
minibatchiterator: epoch 0: frames [0..1124823] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
randomordering: 0 retries for 1124823 elements (0.0%) to ensure window condition
randomordering: recached sequence for seed 0: 128042, 767369, ...
recoverblock: recovering feature block 0 [0..65535)
recoverblock: recovering feature block 1 [65536..131071)
recoverblock: recovering feature block 2 [131072..196607)
recoverblock: recovering feature block 3 [196608..262143)
recoverblock: recovering feature block 4 [262144..327679)
recoverblock: recovering feature block 5 [327680..393215)
recoverblock: recovering feature block 6 [393216..458751)
recoverblock: recovering feature block 7 [458752..524287)
recoverblock: recovering feature block 8 [524288..589823)
recoverblock: recovering feature block 9 [589824..655359)
recoverblock: recovering feature block 10 [655360..720895)
recoverblock: recovering feature block 11 [720896..786431)
recoverblock: recovering feature block 12 [786432..851967)
recoverblock: recovering feature block 13 [851968..917503)
recoverblock: recovering feature block 14 [917504..983039)
recoverblock: recovering feature block 15 [983040..1048575)
recoverblock: recovering feature block 16 [1048576..1114111)
recoverblock: recovering feature block 17 [1114112..1179647)

04/06/2016 12:26:56: Precomputing --> Completed.


04/06/2016 12:26:56: Starting Epoch 1: learning rate per sample = 0.000781  effective momentum = 0.000000  momentum as time constant = 0.0 samples
minibatchiterator: epoch 0: frames [0..2048] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses

04/06/2016 12:26:56: Starting minibatch loop.
04/06/2016 12:26:56:  Epoch[ 1 of 1]-Minibatch[   1-   5, 31.25%]: SamplesSeen = 640; TrainLossPerSample =  5.12473259; EvalErr[0]PerSample = 0.96562500; TotalTime = 0.0293s; SamplesPerSecond = 21810.3
04/06/2016 12:26:56:  Epoch[ 1 of 1]-Minibatch[   6-  10, 62.50%]: SamplesSeen = 640; TrainLossPerSample =  4.91631737; EvalErr[0]PerSample = 0.93750000; TotalTime = 0.0205s; SamplesPerSecond = 31210.4
04/06/2016 12:26:56:  Epoch[ 1 of 1]-Minibatch[  11-  15, 93.75%]: SamplesSeen = 640; TrainLossPerSample =  4.93558578; EvalErr[0]PerSample = 0.96406250; TotalTime = 0.0205s; SamplesPerSecond = 31288.2
04/06/2016 12:26:56: Finished Epoch[ 1 of 1]: [Training Set] TrainLossPerSample = 4.992157; TotalSamplesSeen = 2048; EvalErrPerSample = 0.95751953; AvgLearningRatePerSample = 0.00078125001; EpochTime=0.077667
minibatchiterator: epoch 0: frames [0..122487] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
randomordering: 0 retries for 122487 elements (0.0%) to ensure window condition
randomordering: recached sequence for seed 0: 53396, 47929, ...
recoverblock: recovering feature block 0 [0..65535)
recoverblock: recovering feature block 1 [65536..131071)
Final Results: Minibatch[1-957]: SamplesSeen = 122487    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.8953937    Perplexity = 133.67263    EvalErrorPrediction: ErrorPrediction/Sample = 0.95672194    
04/06/2016 12:26:58: Finished Epoch[ 1 of 1]: [Validation Set] TrainLossPerSample = 4.8953937; EvalErrPerSample = 0.95672194
04/06/2016 12:26:58: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160406132644.85264\Examples\Speech\TIMIT_AdaptLearnRate@release_gpu/exp\TrainAdaptLR\model\cntkSpeech.dnn'
biggrowablevectorarray: deleted disk backup store at 'F:\cygwin64\tmp\CNT38F9.tmp'
biggrowablevectorarray: deleted disk backup store at 'F:\cygwin64\tmp\CNT301E.tmp'
04/06/2016 12:26:58: CNTKCommandTrainEnd: TIMIT_TrainAdaptLR

04/06/2016 12:26:58: Action "train" complete.

04/06/2016 12:26:58: __COMPLETED__